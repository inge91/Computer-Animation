\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{Computer Animation Essay\\ Automatic Rigging Methods}
\author{Inge Becht\\ 4157281}
\date{\today}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Introduction}
%what is skeletal animation?
In computer animation, skeletal animation is often used as an intuitive method
for modeling characters. When applying skeletal animation, the created mesh
model is provided with an underlying hierarchical skeleton, which is attached to
the model, that specifies how the mesh should be deformed in case of movement. The process of forming
the underlying skeleton and fitting it to the model is called rigging, and is
normally done by hand, using 3D modelling software, like for example Maya or
Blender.
%why is it used?

%why is it problematic?
Rigging by hand, however, can be a rather daunting task for beginning 3D
modelers \citep{paper1}, but also a time consuming job for expert animators, as
each model needs to be rigged separately, even though their anatomy might be
quite a like.
%What is automatic rigging?
In this essay, we explore the concept of automatic rigging. As indicated by the
name, the main idea of automatic rigging is that no outside intervention is
needed to rig the model.
%What are the papers that will be studied? What are their methods?
Various papers are written about the subject. We will limit ourselves to
the works of Baran and Popovi\'{c}\citep{paper1}, Pan et al. \citep{paper2} and
Pantuwong and Sugimoto \citep{paper3}, which have found
diverse solution to the proposed problems, which nicely represent the current
state of automatic rigging methods.
%What are some criteria that should be dealt with?
The automatic rigging methods proposed in the research papers need to meet
certain criteria to be considered good. We will evaluate the research on the
following aspects which we find important, of which some are proposed by the
researches themselves:

\begin{itemize}
    \item Performance: The process should not take longer than manual rigging, and
        preferably be faster than that.
    \item Generality: The process should be applicable on a great diversity of models.
    \item Self sufficiency: The process should minimize constraints on the user.
\end{itemize}
These criteria will be our guideline while evaluating the proposed automatic rigging processes.

%Small Summary of what will be found in the paper.
The outline of this essay is as follows. First we will talk about the methods
utilised by the different researches, to give a good understanding of their
differences and their motivation. Giving these differences, we will talk about
their resulting performance giving the above
mentioned evaluation points. After this, we discuss the specific applications to
which each mentioned technique could be applied. Lastly, the conclusion follows.

\section{Method}
Rigging a character can be subdivided in two consecutive steps. The generation
and placement of the skeleton inside the model, and the skinning part, where it
is specified how the mesh is deformed by the skeleton structure. In this section we will talk
about the approach each research takes, and the motivation for
taking that specific approach.

\subsection{Skeleton generation and placement}
The first part of the rigging process, generation and placement of the skeleton, 
is done by one of two distinct approaches, namely skeleton
embedding and skeleton extraction. In the case of skeleton embedding, there
is a fixed skeleton template ready to be embedded into a character model,
in some optimal way. Skeleton embedding is used by
Baran and Popovi\'{c}\citep{paper1}, in which a template for biped and quadruped skeletons is
embedded in character models. In the case of skeleton extraction there
are no template skeletons, but the skeleton is extracted by evaluating the
interior of a model. Skeleton extraction is used by Pan et al.\citep{paper2},
making a diverse set of character rigging possible.
Pauntowing and Sugimoto \citep{paper3} use a combination of the two approaches.

Next we will give a more in depth explanation of each approach.

\subsubsection{Skeleton embedding using continuous optimization}
In the case of skeleton embedding we require pre-made skeletons to be embedded into the mesh,
and a function that determines the optimal way to embed the skeleton.
Baran and Popovi\'{c} used a single biped skeleton to be fitted onto
humanoid meshes, and a quadruped skeleton to be used on quadrupedal characters.
In their approach the volume of the to be rigged mesh is discretized for
computation efficiency and the final placement is determined using a method
called optimal margin optimisation.

To embed the skeleton in an optimal way, first a discretization of the
existing volume takes place, so not the complete space is considered for the
skeleton placement. To this end, the medial surface of the mesh is found. The
medial surface is like the medial axis, but for a 3D space. A point in the space
belongs to the medial axis, when it has more than one closest points on the
model surface. Logically, The medial surface consists of points centered in the model,
where one would expect to find the find skeletal structure. Figure
\ref{fig:discretization}
 shows the medial surface on the left.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{discretization_step.jpg}
    \caption{Discretization steps. Left shows the medial surface, middle shows
    the sphere packing, right shows the graph.}
    \label{fig:discretization}
\end{figure}

Ideally, we would like to be the final embedding space more discrete than the
medial surface, as this still contains a lot of points where we would not want a
joint to be placed. Therefore, we create a final graph using a method very
similar to sphere packing.
Each point on the medial surface, starting with the one furthest from the mesh,
adds a sphere with that point as the center and with the radius the shortest distance
to the mesh. A sphere is not added if it contains the center of another
sphere\footnote{This is different than sphere packing, as spheres in that case
do not intersect at all.}. Figure \ref{fig:discretization} shows the sphere
packing in the middle image.

The final graph is then constructed, sphere
centers become vertices and edges are placed between intersecting spheres, or
in case this edge is essential (which is the case if the vertices are Gabriel
neighbours and are deep enough in the mesh).
Figure \ref{fig:discretization} shows the final graph on the
right. Each vertex in the graph is a potential position for the joints to be
embedded, and each edge is a potential connection point between joints.

Now that de space is discretized, the template skeleton must be somehow embedded
into this graph. To find a desirable fitting, undesired embeddings should be penalized. Possible
aspects of such undesirable embeddings are short bones, improper orientation
between joints, length difference in bones marked symmetric\footnote{markings
are little labels given to the skeleton that help decide where to put each
extremity in the graph.}, bone chains
sharing vertices (there should not be loops in the skeleton), bones marked feet away from the
bottom, zero-length bone chains, improper
orientations of bones, and joints close together in the graph, but far away in
skeleton\citep{paper1}. To find the optimal weight for each penalty function, a
maximum margin linear classifier is learned. 
This approach is called a maximum margin classifier because it tries 
to maximize the margin between the best bad and best
good embedding (as labeled in the training set):

\begin{align}
    \min^n_{i = 1} \Gamma^{T} \textbf{q}_i - \min^m_{i = 1} \Gamma^{T}
    \textbf{q}_i  \label{eq:max}
\end{align}

Where $\textbf{p}$ and $\textbf{q}$ are feature vectors(of the penalties
mentioned earlier) of good and bad
embeddings respectively, $\Gamma$ is the vector containing weights and n and m
are the number of good and bad embeddings.
Ideally we would like the choice of $\Gamma$ so that \ref{eq:max} is maximized, 
as this creates a clear division between embedding of correct and incorrect classifications. 

The learning procedure itself is conducted using Nelder-Mead. It starts off with
random starting values for the weights, which are evaluated using equation
\ref{eq:max}, which should be maximized on a training set of hand classified
character embeddings. 
Because Nelder-Mead can get stuck in local minima, this is run for multiple instances with different initial weights.

Now that we have a way to penalized bad embeddings, the optimal embedding can
 be calculated. To reduce the search space somewhat more, all degree two joints
 (like knees and elbows) are removed from the
skeleton to fit, giving a simplified skeleton to be fitted. The search for the
optimal embedding is done by implementing A*, By using a priority
queue and extending the skeleton one bone at a time. The score of each partial
embedding is the sum of the penalty between each two linked joints in the
partial embedding added to a term that starts with the penalty of the first two
joints added to the penalty of the first three joints and so on until the
last embedded joint. The algorithm stops in case
one embedding is completed, which is assured the optimal one.

When the final fit is found, the merged joints are reinserted by breaking up the
found edges in proportion to the original skeleton, and a final optimisation
step takes place to make sure these joints are nicely positioned inside the
mesh, the bones are of decent length (with regards to the skeleton we started
out with) and the orientation of the bones are as desired.

\subsubsection{Skeleton extraction using 3D silhouettes} Skeleton embedding
might seem like a rather straightforward choice for solving the automatic
rigging problem, but it has its disadvantages. The most notable one is that it
makes the assumption that the user, or the algorithm itself, has predefined
skeletons which will fit the input model. This makes the performance of the
automatic rigging method limited to the diversity of characters that can be
rigged, and not self-sufficient in the case that it accepts skeletons prepared
by the users. 

The use of skeleton extraction circumvents the issue of needing a predefined
skeleton, by looking for the skeletal property within the mesh self. Pan et al.
\citep{paper2} take this skeletal approach.

% what is the medial axis and why is it used
To extract the skeleton from a mesh, Pan et al. use the medial axis as a
guideline for finding the final animation skeleton.
We saw in the case of Baran and Popovi\'{c} that all points in the mesh that had
more than 1 closest point to the mesh are surfaces, but for a 2D object the medial axis will consists of
curves. These curves can be quite straightforwardly converted to a skeleton, as
it gives the exact centered placement for the bones within the mesh. Pan et al.
use 3D silhouettes, two dimensional projections with the depth information stored along
the silhouette, to find the medial axis of a 3D model.

To take the 3D silhouette from a mesh, first the optimal projection of the model
onto a two dimensional plane must be determined. An optimal projection is a
projection in which there is as little occlusion as possible, so that when
determining the medial axis, all parts of the character model are considered.
The optimal projection is thus considered the projection with the maximum
surface area. When this projection is determined, a global and a local search
are used to determine the 3D silhouette. 

In the global search the vertices making up the 3D silhouette are determined. 
The first vertex that is selected is the most top one in the silhouette and
every new selected vertex is found by looking in the counter clockwise
direction within a radius, whose size is determined by the maximal distance with
which the current vertex is connected in the mesh. 

When the vertices belonging to the 3D silhouette are found using global search,
it is very likely these points are not connected in the mesh, due to
differences in depth between these vertices. The local search finds the shortest
route between every vertex of the 3D silhouette, and adds these in-between
vertices to the 3D silhouette vertices. Adding these vertices will add more
detail to the medial axis. %FIXME is this really the case?

After the 3D silhouette is found, the medial axis can be determined. This is
achieved by filling the silhouette with triangles, using Delaunay
Triangulation. For each triangle edge that is not on the boundary of the
silhouette, the midpoint is calculated. These points are then connected using
linear interpolation, creating one or multiple curves within the mesh. By
considering only the inner edges of the triangles, it is assured that none of
the curves make contact with the mesh boundary, which is desirable for the final
skeleton, as it will be well centered within the mesh.

Because the silhouette contains vertices of different depth, the current curve
skeleton will not be centered in the plane that was ignored by projection. This
causes the medial axis calculation to be slightly off center. This is fixed
by looking for a perpendicular projection to the one used for the initial
silhouette creation. This is done for every curve by finding the projection
vector that is orthogonal on both the curve and the previous projection vector.
For this new projection the 3D silhouette is determined the same way as before.
The final refinement of the curve skeleton is for every element of the curve
finding the four nearest neighbours on the second silhouette, and then
interpolating between these four points.

When the medial axis is refined, the different curves need to be combined to a
single skeleton. All endpoints between each curve is considered a joint, and are
connected together. These, however are not all the joints in the skeleton only
the junctions between different limbs. To determine where the degree two
joints should be positioned in this skeleton, the authors look at the degree of
bending in the extracted curve. If the bending angle between positions on the curve is 
significant (which in this research means more than 18 degrees of bending), a
joint is added at that position.

\subsubsection{Combining embedding and extraction} Although skeleton extraction
can handle more generic cases than skeleton embedding, due to not needing any
prior knowledge on the topology of the character, there is also the
disadvantage in that the model must be expressive enough for the skeleton to be
correctly  extracted. We see this clearly in the way that
second degree joints need to be determined in the works of \citep{paper2}. Take
for example the case of a humanoid model standing in T-Pose (not an uncommon
pose to model a character in). If this skeleton extraction algorithm were to be run for
this particular model, it's output skeleton would be likely missing its elbow and knee
joints. 

\citep{paper3} suggests a method that combines embedding and extraction in such
a way that the extracted curve skeleton becomes the embedding space on which semantic
judgement can be made about what kind of character is being depicted by the
model.
The best-fitting template-skeleton can then be embedded in the model my aligning it with the curve skeleton..

The researchers use a curve extraction method called pseudo normal vector fields
which has been a result of earlier results, but any curve extractor that uses
distance fields could be used (so the method in \citep{paper2} is not ideal to
apply in this case). After the curve skeleton is extracted, the
curve is preprocessed. This preprocessing step makes sure that so called
symmetry segments come together at a single junction point. Symmetry segments
are limbs that should be paired together. So in case of a human, the arms would
be symmetry segments, and the legs would be symmetry segments. In case there are
two different junctions whose difference in distance is small to any endpoint of
the curve, the two junctions are merged together.

Now that we are certain that symmetric segments of the model come
together in junction points, this can be exploited towards determining what kind
of creature is being depicted by the model. To get any substantial understanding
of the topology of this curve skeleton, however, we need to determine what are
the symmetry segments and what is the symmetry axis. The symmetry axis is the
curve to which all extremities are connected (for a human model, this would be
considered the spine). To determine which is which, the
junction closest to the centroid of the character is found. The two longest
segments attached to this junction are considered the limbs, the remaining
segments are automatically part of the symmetry axis in case there are only one
or two segments at the junction left. In case there are more than two, the
remaining segments are first divided in groups that end up in other junction
points, and others that end up in an extremity. The symmetry axis segments are
then segments from the first group that make the biggest angle. In case there
are one or less segments available in here, segments from the second group are
used as well. This is repeated for every new junction node found on the symmetry
axis, until the complete symmetry axis is found.

Being able to discover the symmetry axis using the method above, a
classification can be made about what the input model depicts. A very rough
first classification step uses the limbs to determine the character class. These
classes are:  a snake in case of zero junctions on the skeleton,
a bird (with its wings or legs fold up) or fish (single fin in the back)in case
of a single junction. The humanoid and quadruped skeletons fall into the next
category of two junction characters. The last class is for 3 junction
characters, under which humanoids with horns, quadrupeds with ears and birds
(with wings, tail and legs) fall.

To distinguish between characters of each class, the placement and orientation
of the junctions are checked, as well as the symmetry segment length. Because
of the length of the complete list, we will only mention a few concrete
characteristics the example looks for. For example, to distinguish between
fish and birds in the 1 junction class, the placement of the junction is
examined. If this junction is at the end of the symmetry axis, it is probably a
fish fin. If the junction is midway, it can be the wings of a bird in case the
angle between the symmetry segments is about 180 degrees, and else it will be the
legs of a bird. In the 2 junction case, the thickness of
limb is taken into account to distinguish between mammals and fish and birds.
The distinction between bipeds and quadrupeds is made by looking at the normal
vectors of the plane in which the symmetry segments fall for both junctions. If
these normal vectors point the same way, it is considered a quadruped, if not,
it is considered a biped. 

Using these rules and many others, we know the most likely character the model represents, and
what part each symmetry segment is of the final skeleton. Based on this
classification, an appropriate skeleton can be retrieved from a database full of
template skeletons. Each segment of this skeleton is then mapped on the desired
position of the curve skeleton. The junction position is done by keeping the
same ratio to the segment endpoints as is the case in the template skeleton.

\subsection{Evaluation}
With the differences in methodology explained, we will now evaluate the
approaches regarding their performance, quality, self-sufficient, generality and
further limitations.

\subsection{Performance}
Speed is an important factor when it comes to the evaluation of the automatic rigging
methods. Ideally, we would like the time in which the rigging takes place is
faster than doing it by hand. \citep{paper1} has tested their algorithm on 16
different models. The shortest time was 12.6 seconds for a model containing 19.001
vertices. The longest time was 77.1 seconds for a model with 56.856 vertices.
The most time is spend on the preprocessing steps, due to the calculation of the
distance field. The embedding itself takes about a fifth of the complete
computation time, but varies a lot.

\citep{paper2} give the result of their algorithm applied to five different
character models. Their shortest time is 3.6 seconds for a model containing
16.834 faces and their longest time recorded is 15.1 seconds for a model
containing 52.895 faces.
\citep{paper3} only states the computation time for the model with biggest
volume, which is 30 seconds.

Although these performances can not be compared side by side due to the test
being ran in different circumstances, all of them were applied on everyday
computers \footnote{Tests by \citep{paper1} were run on a 1.73 MHz Intel Core Duo
    with 1GB RAM.\\ Tests by \citep{paper2} were run on a 1.6GHz Intel Core Dual PC
    with 1GB RAM.\\
Test by \citep{paper3} were run on a 2.4-GHz Intel Core Dual PC with 1GB RAM.}
, making all three methods seem to perform fast enough to be preferred than
manual rigging. 

It is also interesting to note the time complexity of the different methods.
The time complexity of the first algorithm falls in $O(N^2)$, due to the
embedding being done using A-Star.
The complexity of the algorithm of \citep{paper2} is in $O(N)$, with the bottle
neck probably being finding the primary silhouette.
The complexity of the algorithm of \citep{paper3} depends on the amount of
voxels in the reconstruction, where complexity falls in $O(N^2)$, with N being the
amount of voxels.
From this we can observe that \citep{paper2} would probably scale the best to
complexer model when it comes to computation time.

\subsection{self-sufficiency}
Ideally we would like the end user to have little
to no extra work when using the rigging algorithm. Things like pose restrictions
and user guidance throughout the rigging process should be at a minimum.

In all three methods, the success of the rigging procedure is very reliant on
the way the input model is presented. For \citep{paper1} the input pose is
heavily restricted. The pose should match the one of the template skeleton as
much as possible, as the penalty function penalizes different orientation in the
placement of the bones as that on the skeleton, and also expects the feet to be
ad the bottom of the model.
For \citep{paper2} the pose restriction is of importance due to two different
reasons: occlusion and second-degree joint placement. The first means we would
like an optimal projection in which no occlusion takes place. Because the median
axis extraction is based on silhouettes, the skeleton will not properly
represent the model. Take for example a model if a fist. If the medial axis is
taken from the projection with the largest surface, the extracted axis would
probably form an L-shaped curve, with no sign of the fingers.
The second restriction has already been mentioned before, but forms a real problem if we
think about limbs with high flexibility. To show the bending properties of the limbs it requires
the complete limb being bend at every possible position, making for a
non-intuitive modelling (like, for example, not putting bipeds into the T-Pose).

Of the three approaches, the approach by \citep{paper3} has the least
restriction regarding the input. The fact that this
is not restricted is due the semantic interpretation that is made by the model,
where an interpretation is made for each extremity of the model, instead of
assuming the feet are at the bottom. It does, however make some assumptions.
For example, there should be a 90 degree angle between feet and ankles to
determine the front side and backside of a human, and a human should not be
positioned like a quadruped else it will be classified as one.
These might seem like obvious decisions when modeling, but these
classification rules are not completely clear for outside users.

\subsection{Generality}
Ideally we would like the rigging methods applied to be as general as possible,
meaning that a single method could be used for all kinds of different input
character, and have a desired outcome.

The method developed by \citep{paper1} has only been elaborately tested on the
embedding of a biped skeleton \footnote{they mention also an experiment with a quadruped
skeleton and centaur skeleton embedding, but do not give any substantial information
about the process, giving the impression it is not at all extensively tested.}
template on sixteen different input character models, as shown in figure
\ref{fig:results1.png}. Most of these models were
correctly rigged, only model 7, 10 and 13 did not get the desired rigging. These
however, could be corrected by the user giving a single hint of a correct joint
placement.

Also non-typical biped shapes, like for example a donut, have been rigged by \citep{paper1} and gave
successful results.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{embedding_result.jpg}
    \caption{Results of \citep{paper1}}
    \label{fig:results1.png}
\end{figure}

Although we can say that the method of \citep{paper1} works fairly well for
quite a big range of models, not limited to clearly biped models, it is lacking for a big range of other characters
as well. Most animals will not be successfully rigged due to them being quadruped
(or higher)
in nature. In theory, the approach taken by \citep{paper1} could be extended for
non-humanoid models, by instead of fitting a single template to the input model,
try out all different possible skeleton
embeddings. After trying out these different embeddings, the embedding with the
smallest penalty can then be returned. This expansion to the algorithm, however,
has its own problems. Firstly, is the issue of computation time. All those different embeddings can give a 
huge overhead. Although we have seen that the most computation expensive part is
the distance field calculation in the discretization step, the embedding takes
at average one fifth of the complete computation time. Moreover, the
embedding time is worst case exponential due to the way A* is implemented, 
and it is hard to predict the actual running time for each case.
Another issue, all be it small, is the current penalty function. Although most parts of the penalty
function are straightforward, and applicable to different kind of template
skeletons, the penalty for small bones makes the embedding of tail-having
creatures, or snakes, or octopi, or just any character having an extremity
consisting of many small bones problematic. This could of course be added by the constraints
by ignoring size of bones labeled \emph{tail}, but in its current form this can
be problematic, and for that reason should be mentioned. In case the penalty
function is not changed, nothing has to be relearned, which is a plus.
A last point that should be mentioned is a problem that can not be fixed, due to
the skeleton embedding approach, which is that the best possible fitting
skeleton might still not be the desired skeleton. As we have stated before, the
method of embedding is limited to the skeletons that were fed the to algorithm
beforehand, making it impossible to create new fantastical creations without
the user having to do half the rigging process herself.

In the works of \citep{paper2} the problem of needing pre-existing templates may
not be present, but this does not mean that every automatic rigging of a model will have a
desirable outcome. Firstly, using the medial axis as strict guideline for the
final skeleton makes the assumption that the models is constructed out of
elements that approximate cylindrical shapes. If this is not the case, the skeleton will not be centered,
making the final mesh deformation using the skeleton look off. The
authors themselves mention this problem occurring in case of rigging for example a \emph{rock
with grotesque shape}. This might not seem like the most convincing example, as
skeletal animation is not something one would normally think about when
animating a rock, but the problem holds for other examples as well. For example,
a model of a cartoonishly muscular man in flexing pose will end up having
non-straight curves in its arm that follow the shape of the muscle, instead of
the natural bone placement. The biggest disadvantage here is that not a very
good estimate can be made in advance if an input model will be correctly rigged
or not.
Nonetheless, there are a wide range of character for which this approach to
rigging can have a very beneficial effect, in their tests bipeds, quadrupeds,
octopeds and a model of a hand were all successfully rigged.

Due to the combination of embedding and extraction in the approach by \citep{paper3},
we see some of the above issues arise for this specific approach as well.
The generality of this rigging approach is again limited to the template
skeletons available in the database, and the way the curve skeleton is
extracted.
An advantage in comparison with the method in \citep{paper1} is that the
algorithm can select from different skeletons to choose the appropriate one,
with often good results. The results are shown of over 12 different models, all
of different character classes, which
all were correctly classified and rigged. 

This classification procedure, however, does not work by applying 
all possible embeddings and returning which works
best, but chooses one on previously discusses criteria. These criteria are
however kind of crudely stated, and could cause misclassification in the less
obvious cases. This could possibly have better effect when using a penilization
function as in the case of \citep{paper1}, where every embedding is tried out
and the best one is returned. This is shown in the case of their embedding of
case 8. This goes wrong for \citep{paper3} due to the hat being interpreted as
horns. This specific misclassification is not too problematic,
but this same issue can arise for the anatomical information
extraction. One of the rules for the anatomical interpretation of humanoid
characters with horns or ears is that the shortest symmetry segments will be
considered the ears or horns .This will go wrong in the case of a
rabbit like-figure, whose ears might be longer than any other extremity.

%paper 3 only wants a logical position of the mesh


% In case of paper 2

\section{Application}
The three applications of automatic rigging that we have studied are all to some
extent viable options for easy rigging, but due to their qualitative differences, 
the domains in which they can be best applied differ quite a lot.
Here we will discuss some practical applications that we envision for these
different methods.

As we have seen in the evaluation, \citep{paper1} is currently limited to biped
character rigging, but can correctly rig cartoonish looking  characters. In addition, it can be
corrected by an end user that does not really need to know much about the 3D
modelling process. Therefore, it would be interesting to integrate this method into
frameworks where 3D models are created from 2D drawings and sketches. Some
previous research with promising results has already been done in this topic
\citep{paper4}, but the rigging part has not yet been integrated. If this automatic rigging
algorithm is used, where the template skeleton is equipped with some basic
animations, a 2D artist of any kind could easily create its own 3D model to
deploy in movies or games as long as it is biped and has a pose similar to that
of the skeleton.

Due to the method of \citep{paper2} setting heavy restrictions on input pose,
not having a clear boundary of what can be correctly rigged, and not
having an easy way to correct the final rendering without 3D modelling software
or limited knowledge, its use seems strictly limited to experts in the field of 3D
modelling, that would like a less cumbersome method of rigging. This method
could save a lot of time for more demanding characters, like spiders or other
character with many extremities.

We have seen that the approach of \citep{paper3} works best for realistic
models, but that it still is restricted due to the template skeleton that needs
to be available. It would be great if the database could be easily expanded upon

\section{Conclusion}
In this essay we discussed skeletal animation as an important method for
animating character models. The way such models are rigged can be a rather
cumbersome task, and daunting for beginners in the field of animation. A lot of
research has been done towards automatic rigging algorithms. We looked at three
different methods. A skeletal embedding approach by Baran and Popovi\'{c} \citep{paper1}, a skeletal
extraction approach by Pan et al. \citep{paper2} and a method by Pantuwong and
Sugimot \citep{paper2} that
combines the two methods. First we gave some motivational inside for each
approach and explained what their method entailed. After this we evaluated each
approach on three different aspects that seem important for the algorithm; speed
performance, generality and self-sufficiency. 

We saw that the skeleton embedding approach by \citep{paper1} currently has only
been extensively tested on biped meshes, and has limited problems with rigging a
wide variety of these models, all which could easily be explained due to their
applied method. Due to the algorithms speed and possibility to apply correction
without needing any knowledge of modelling or rigging, we envision this method
as part of systems that bring 3D modelling to 2D artists that have no prior
knowledge of 3D modelling.
The skeletal extraction approach by \citep{paper2}, due to it not being restricted to provided
template skeleton, has the most freedom in the kind of models it could rig, but
makes a lot of restrictions on the incoming modeller, making the use more
constraint. It is also not directly clear what can and cannot directly be
rigged, making it at best a tool for expert modellers. 

The combined approach could rig a wide range of diverse characters, but is mostly
limited to models with realistic proportions, and didn't


\bibliographystyle{plain}
\bibliography{references}
\end{document}
