\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Computer Animation Essay\\ Automatic Rigging Methods}
\author{Inge Becht\\ 4157281}
\date{\today}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Introduction}
%what is skeletal animation?
In computer animation, skeletal animation is often used as an intuitive method
for modeling characters. When applying skeletal animation, the created mesh
model is provided with an underlying hierarchical skeleton, which is attached to
the model, and specifies how the mesh can be deformed. The process of forming
the underlying skeleton and fitting it to the model is called rigging, and is
normally done by hand. 
%why is it used?

%why is it problematic?
Rigging by hand, however, can be a rather daunting task for beginning 3d
modelers \citep{paper1}, but also a time consuming job for expert animators, as
each model needs to be rigged separately, even though their anatomy might be
quite a like.
%What is automatic rigging?
In this essay, we explore the concept of automatic rigging. As indicated by the
name, the main idea of automatic rigging is that no outside intervention is
needed to rig the model.
%What are the papers that will be studied? What are their methods?
Various papers are written about the subject. We will mostly limit ourselves to
the works of \citep{paper1}, \citep{paper2} and \citep{paper3}, which have found
diverse solution to the proposed problems, all with their own pros and cons.
%What are some criteria that should be dealt with?
The automatic rigging methods proposed in the research papers need to meet
certain criteria to be considered good. We will evaluate the research on the
following aspects which we find important, of which some are proposed by the
researches themselves:

\begin{itemize}
\item Performance: The process should not take longer than manual rigging, and
    preferably be faster than that.
\item Generality: The process should be applicable on a great diversity of models.
\item Self sufficiency: The process should minimize constraints on the end user.
\item Robustness: In case modeling goes wrong, it is desirably easily fixable.
\end{itemize}
These criteria will be our guideline while evaluating the proposed automatic rigging processes.

%Small Summary of what will be found in the paper.
The outline of this essay is as follows. First we will talk about the methods
utilised by the different researches, to give a good understanding of their
differences. Giving these differences, and their advantages and disadvantages on
a high level, we will talk about their resulting performance giving the above
mentioned evaluation points. After this, we discuss the specific applications to
which each mentioned technique will be applied. Lastly, the conclusion follows.

\section{Method}
Making a character mesh come to life consists of two specific parts. The rigging
of the character, as explained in the introduction, and the skinnning, where the
deformation of the mesh is assigned to the bones. In this section we will talk
about the specific approaches for each paper for these two steps.

\subsection{Skeleton generation}
    \subsection{Skeleton embedding and skeleton extraction}
Automatic rigging is done by one of two distinct approaches, namely skeleton
embedding and skeleton extraction. In the case of skeleton embedding, there
is a fixed skeleton template ready to be embedded into a character model,
using an optimisation function. Skeleton embedding is used by
\citep{paper1}, in which a template for biped and quadruped skeletons is
embedded in character     models. In the case of skeleton extraction there
are no template skeletons, but the skeleton is     extracted using the
topology of the character. Skeleton extraction is used by \citep{paper2},
making a diverse set of character rigging a possibility.

Both skeleton embedding and skeleton extraction have their advantages and
disadvantages, which     we will discuss next. We will discuss these aspects in
the following sections, where we talk     about the problems more in depth. 

In \citep{paper3} both extraction and embedding are combined, in the attempt to    

\subsubsection{Skeleton embedding using continuous optimization}
In the case of skeleton embedding, there are some prerequisites. It requires pre
made skeletons to be embedded into the mesh, and a function that determines the
optimal way to embed the skeleton. 
The authors of \citep{paper1} used a single biped skeleton to be fitted onto
humanoid meshes, and a quadruped skeleton to be used on quadrupedal characters.
In their approach the volume of the to be rigged mesh is discretized for
computation efficiency and the final placement is determined using optimal
margin optimisation.
 
To create an optimal embedding of the skeleton, first a discretization of the
existing volume takes place, so not the complete space is considered for the
skeleton placement. To this end the medial surface of the mesh is found, which
contains the inner volume of where one would expect to find skeletal structure.
The median surface is found by creating a distance field.
 
The final discretization is a graph in which each vertex is a candidate for a
joint position of the skeleton and each edge is a candidate bone position
belonging to the joints \citep{paper1}. 
 
To find a desirable fitting, undesired embeddings should be penalized. Possible
aspects of such undesirable embeddings are short bones, improper orientation
between joints, length difference in bones marked symmetric, bone chains
sharing vertices, feet away from the bottom, zero-length bone chains, improper
orientations of bones and joints close together in the graph, but far away in
skeleton\citep{paper1}. To find the optimal weight for each penalty function, a
maximum margin linear classifier is learned.  This approach is called maximum
margin because it tries to maximize the margin between the best bad and best
good embedding (as labeled in the training set), so that there is a clear
embedding of correct and incorrect classifications. The learning procedure
itself is conducted using Nelder-Mead{explain more in depth how}.

The optimal embedding of the skeleton is now calculated using A*. To reduce the
search space somewhat more, all second degree joints are removed from the
skeleton to fit, giving a simplified skeleton to be fitted. By using a priority
queue and extending the skeleton one bone at a time, the algorithm stops in case
one embedding is completed, as it is assured the optimal one.

When the final fit is found, the merged joints are reinserted by breaking up the
found edges in proportion to the original skeleton , and a final optimisation
step takes place to make sure these joints are nicely positioned inside the
mesh, the bones are of decent length (with regards to the skeleton we started
out with) and the orientation of the bones are as desired.


\subsubsection{Skeleton extraction using 3D silhouettes} Skeleton embedding
might seem like a rather straightforward choice for solving the automatic
rigging problem, but it has its disadvantages. The most notable one is that it
makes the assumption that the user, or the algorithm itself, has predefined
skeletons which will fit the input model. This makes the performance of the
automatic rigging method limited to the diversity of characters that can be
rigged, and not self-sufficient in the case that it accepts skeletons prepared
by the users. 

The use of skeleton extraction circumvents the issue of needing a predefined
skeleton, by looking for the skeletal property within the mesh self. Pan et al.
\citep{paper2} take this skeletal approach, which will be explained next.

% what is the medial axis and why is it used
To extract the skeleton from a mesh, Pan et al. use the medial axis as a
guideline for finding the final animation skeleton. The medial axis consists of all points that have more than one
closest point on the boundary of the object. In other words, it consists of
point within the model that are centered with regards to the boundary of the
mesh. In case the medial axis is determined for a three dimensional shape, it most likely
is a surface (called the medial surface, as we have seen before in the case of
paper \citep{paper1}) but for a 2D object the medial axis will consists of
curves. These curves can be quite straightforwardly converted to a skeleton, as
it gives the exact centered placement for the bones within the mesh. Pan et al.
use 3D silhouettes, two dimensional projections with the depth information stored along
the silhouette, to find the medial axis of a 3D model.

To take the 3D silhouette from a mesh, first the optimal projection of the model
onto a two dimensional plane must be determined. An optimal projection is a
projection in which there is as little occlusion as possible, so that when
determining the medial axis, all parts of the character model are considered.
The optimal projection is thus considered the projection with the maximum
surface area. When this projection is determined, a global and a local search
are used to determine the 3D silhouette. In the global search the vertices
making up the 3D silhouette are determined. 

When the vertices belonging to the 3D silhouette are found using global search,
it is very likely these points are not connected in the mesh, due to
differences in depth between these vertices. The local search finds the shortest
route between every vertex of the 3D silhouette, and adds these in-between
vertices to the 3D silhouette vertices. Adding these vertices will add more
detail to the medial axis. %FIXME is this really the case?

After the 3D silhouette is found, the medial axis can be determined. This is
achieved by discretizing the silhouette in triangles, using Delaunay
Triangulation. For each triangle edge that is not on the boundary of the
silhouette, the midpoint is calculated. These points are then connected using
linear interpolation, creating one or multiple curves within the mesh. By
considering only the inner edges of the triangles, it is assured that none of
the curves make contact with the mesh boundary, which is desirable for the final
skeleton.

Because the application of the delaunay triangulation did not take the depth
into account, the medial axis calculation might be slightly off center. This is fixed
by looking for a perpendicular projection to the one used for the initial
silhouette creation. This is done for every curve by finding the projection
vector that is orthogonal on both the curve and the previous projection vector.
For this new projection the 3D silhouette is determined the same way as before.
The final refinement of the curve skeleton is  every element of the curve
finding the four nearest neighbours on the second silhouette, and then
interpolating between these four points.

When the medial axis is refined, the different curves need to be combined to a
single skeleton. All endpoints between each curve is considered a joint, and are
connected together. These, however are not all the joints in the skeleton only
the junctions between different limbs. To determine where the second degree
joints should be positioned in this skeleton, the authors look at the degree of
bending in the extracted curve. If the bending angle between positions on the curve is 
significant (which in this research means more than 18 degrees of bending), a
joint is added at that position.

\subsubsection{Combining embedding and extraction} Although skeleton extraction
can handle more generic cases than skeleton embedding, due to not needing any
knowledge a priori on the topology of the character, there is also the
disadvantage in that the model must be expressive enough for the skeleton to be
correctly\footnote{This of cou} extracted. We see this clearly in the way that
second degree joints need to be determined in the works of \citep{paper2}. Take
for example the case of a humanoid model standing in T-Pose (not an uncommon
pose to model a character in). If this skeleton extraction algorithm were to be run for
this particular model, it's output skeleton would be likely missing its elbow, and knee
joints. 

\citep{paper3} suggests a method that combines embedding and extraction in such
a way that a semantic judgement is made about the extracted curve, specifying
what kind of character is being depicted in the model. The best-fitting template-skeleton can then
be fitted into the model.

The researchers use a curve extraction method called pseudonormal vector fields
which has been a result of earlier results, but any curve extractor that uses
distance fields could be used (so the method in \citep{paper2} is not ideal to
apply in this case). After the curve skeleton is extracted, the
curve is preprocessed. This preprocessing step makes sure that so called
symmetry segments come together at a single junction point. Symmetry segments
are limbs that should be paired together. So in case of a human, the arms would
be symmetry segments, and the legs would be symmetry segments. In case there are
two different junctions whose difference in distance is small to any endpoint of
the curve, the two junctions are merged together.
% They do not tlak about normalizing the size of the models, so i do not see how
% a single treshold could ever work

Now that we are certain that symmetric segments of the model come
together in junction points, this can be exploited towards determining what kind
of creature is being depicted by the model. To get any substantial understanding
of the topology of this curve skeleton, however, we need to determine what are
the symmetry segments and what is the symmetry axis. The symmetry axis is the
curve to which all extremities are connected. To determine which is which, the
junction closest to the centroid of the character is found. The two longest
segments attached to this junction are considered the limbs, the remaining
segments are automatically part of the symmetry axis in case there are only one
or two segments at the junction left. In case there are more than two, the
remaining segments are first devided in groups that end up in other junction
points, and others that end up in an extremity. The symmetry axis segments are
then segments from the first group that make the biggest angle. In case there
are one or less segments available in here, segments from the scond group are
used as well. This is repeated for every new junction node found on the symmetry
axis, until the complete symmetry axis is found.


Now that the symmetry axis can be 
% Find centroid
% Find closest junction to centroid. This will be on the symmetry axis.
% We look at all segments of this junction. The longest ones are decomposed, the
% shorter ones are considered part of the symmetry axis. If 2 remain, they are
% immediately part of it. If 3 remain

 



%
%We clearly seesome approaches towar
%It makes a very clear space in which the final skeleton will be embedded. It
%also has a better selection procedure for choosing the to be fitted skeleton
%that this approach taken by \citep{paper3} does not remove all
%disadvantages of embedding and extraction. In the case of 
%It also has some limitations, which we will discuss in the evaluation.

\subsection{Skinning}
To pose the model using the skeleton, it still has to be decided how the model
is deformed by the moving skeleton. This process is called skinning. For the
skinning part there is not much diversity between the different researches. All
three apply a method called Linear Blend Skinning, which is a well established skinning method due
to its speeds and performance.

%Talk about how it works

%talk about tome positive and negative approaches 


\subsection{Evaluation}
In this section we will talk about the results of each of the approaches with
regards to time, generality and comparison towards other models.

\subsection{Performance}
%All papers are rather fast in their approach, we could possibly write some more in depth 
%sphere packing in paper 1 O(nb)
% Paper 2 is very fast, because they only have to consider 
\subsection{self-sufficiency}
%paper 1 is very reliant on the pose in which the mesh is delivered. It also uses quick hacks like " the feet are at the bottom" to perform well.
\subsection{Generality}
%Paper 1 can use new skeletons without needing threcalculate the weights, so making it more general, as well as self sufficient
%It does however use 
% even if paper 1 used more than a single skeleton throughout the whole embedding process, it has no criteria on which to fit the models.
% It could possibly for all embeddings check the least penalized embedding, but in the current state this is not implemented.
% Paper2 the generation of the curve skeleton from the medial axis only works in case the basic shape of the 

% Problem: The detail of a skeleton migt be too high for a simpler input model.
% Slight 

\subsection{Limitations}
In case the user already has motion data applied to a skeleton,
the extracted skeleton might make this mapping impossible.  Both skeleton
extraction and embedding have some clear disadvantages, making it hard to 
\subsection{Robustness}
%Paper 1 gives the ability to give hints in case of wrong classification. Such a
%hint can be labeling the vertices like In case there are no vertices at the
%position that are desired to map the skeleton on, there is no way of saving the
%embedding. For example, in case the mesh has rather thin arms, and so the arms
%are not fitted correctly, there is no way of changing the layout, making user
%changes very limited because of the discretization step.

% Paper 2 global search seems robust? in worst case it can always add its
% neighbours to the mesh
\section{Usage}
%The usage of paper 3 is quite clear. It 

\section{Conclusion}
Give a small summary about what is said

What can we conclude about the 3 papers?  All 3 papers seem to have a slightly
different goal wanting to be reached.Paper 3 seems to focus on realistic models
the way their algorithm works (For example, thin legged creatures must be birds,
and so cannot be humans) but it does restrict creative freedom. In paper 1 this
creative freedom is very important to the researchers, but the final application
is very limited, with their a

What do I think is best?
To me, paper 2 seems the most promising in the way it works, as there is no
limitation as to what kind of creatures it can make. A big problem. however, is
the creation of the joint positions. Both relying on the model position showing
angles at every real joint position as well as creating a database of stored
joints is problematic, the first because it relies on the end users for creating
a pose, the latter because it loses the generality it had in the first place
(like we see in the works of paper 3). In my opinion, this part could best be
solved by another solution entirely. In my opinion the first solution is a
better one as the second.

do I have some views myself on how this could be improved?

\bibliographystyle{plain}
\bibliography{references}
\end{document}
