\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Computer Animation Essay\\ Automatic Rigging Methods}
\author{Inge Becht\\ 4157281}
\date{\today}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Introduction}
%what is skeletal animation?
In computer animation, skeletal animation is often used as an intuitive method
for modeling characters. When applying skeletal animation, the created mesh
model is provided with an underlying hierarchical skeleton, which is attached to
the model, and specifies how the mesh can be deformed. The process of forming
the underlying skeleton and fitting it to the model is called rigging, and is
normally done by hand. 
%why is it used?

%why is it problematic?
Rigging by hand, however, can be a rather daunting task for beginning 3d
modelers \citep{paper1}, but also a time consuming job for expert animators, as
each model needs to be rigged separately, even though their anatomy might be
quite a like.
%What is automatic rigging?
In this essay, we explore the concept of automatic rigging. As indicated by the
name, the main idea of automatic rigging is that no outside intervention is
needed to rig the model.
%What are the papers that will be studied? What are their methods?
Various papers are written about the subject. We will mostly limit ourselves to
the works of \citep{paper1}, \citep{paper2} and \citep{paper3}, which have found
diverse solution to the proposed problems, all with their own pros and cons.
%What are some criteria that should be dealt with?
The automatic rigging methods proposed in the research papers need to meet
certain criteria to be considered good. We will evaluate the research on the
following aspects which we find important, of which some are proposed by the
researches themselves:

\begin{itemize}
\item Performance: The process should not take longer than manual rigging, and
    preferably be faster than that.
\item Generality: The process should be applicable on a great diversity of models.
\item Self sufficiency: The process should minimize constraints on the end user.
\item Robustness: In case modeling goes wrong, it is desirably easily fixable.
\end{itemize}
These criteria will be our guideline while evaluating the proposed automatic rigging processes.

%Small Summary of what will be found in the paper.
The outline of this essay is as follows. First we will talk about the methods
utilised by the different researches, to give a good understanding of their
differences. Giving these differences, and their advantages and disadvantages on
a high level, we will talk about their resulting performance giving the above
mentioned evaluation points. After this, we discuss the specific applications to
which each mentioned technique will be applied. Lastly, the conclusion follows.

\section{Method}
Rigging a character can be subdivided in two different stepss. The generation
and placement of the skeleton inside the mesh, and the skinning part, where it
is specified how the mesh is deformed by the skeleton structure. In this section we will talk
about the approach each research takes to this problem, and the motivation for
taking that specific approach.

\subsection{Skeleton generation and placement}
The first part of the rigging pocess, generation and placement of the skeleton, 
is done by one of two distinct approaches, namely skeleton
embedding and skeleton extraction. In the case of skeleton embedding, there
is a fixed skeleton template ready to be embedded into a character model,
using an optimisation function. Skeleton embedding is used by
\citep{paper1}, in which a template for biped and quadruped skeletons is
embedded in character models. In the case of skeleton extraction there
are no template skeletons, but the skeleton is extracted using the
topology of the character. Skeleton extraction is used by \citep{paper2},
making a diverse set of character rigging a possibility.

Both skeleton embedding and skeleton extraction have their advantages and
disadvantages, which we will discuss next. We will discuss these aspects in
the following sections, where we talk about the problems more in depth. 

In \citep{paper3} both extraction and embedding are combined, in the attempt to    

\subsubsection{Skeleton embedding using continuous optimization}
In the case of skeleton embedding, there are some prerequisites. It requires pre
made skeletons to be embedded into the mesh, and a function that determines the
optimal way to embed the skeleton. 
The authors of \citep{paper1} used a single biped skeleton to be fitted onto
humanoid meshes, and a quadruped skeleton to be used on quadrupedal characters.
In their approach the volume of the to be rigged mesh is discretized for
computation efficiency and the final placement is determined using optimal
margin optimisation.
 
To create an optimal embedding of the skeleton, first a discretization of the
existing volume takes place, so not the complete space is considered for the
skeleton placement. To this end the medial surface of the mesh is found, which
contains the inner volume of where one would expect to find skeletal structure.
The median surface is found by creating a distance field.
 
The final discretization is a graph in which each vertex is a candidate for a
joint position of the skeleton and each edge is a candidate bone position
belonging to the joints \citep{paper1}. 
 
To find a desirable fitting, undesired embeddings should be penalized. Possible
aspects of such undesirable embeddings are short bones, improper orientation
between joints, length difference in bones marked symmetric, bone chains
sharing vertices, feet away from the bottom, zero-length bone chains, improper
orientations of bones and joints close together in the graph, but far away in
skeleton\citep{paper1}. To find the optimal weight for each penalty function, a
maximum margin linear classifier is learned.  This approach is called maximum
margin because it tries to maximize the margin between the best bad and best
good embedding (as labeled in the training set), so that there is a clear
embedding of correct and incorrect classifications. The learning procedure
itself is conducted using Nelder-Mead{explain more in depth how}.

The optimal embedding of the skeleton is now calculated using A*. To reduce the
search space somewhat more, all second degree joints are removed from the
skeleton to fit, giving a simplified skeleton to be fitted. By using a priority
queue and extending the skeleton one bone at a time, the algorithm stops in case
one embedding is completed, as it is assured the optimal one.

When the final fit is found, the merged joints are reinserted by breaking up the
found edges in proportion to the original skeleton , and a final optimisation
step takes place to make sure these joints are nicely positioned inside the
mesh, the bones are of decent length (with regards to the skeleton we started
out with) and the orientation of the bones are as desired.


\subsubsection{Skeleton extraction using 3D silhouettes} Skeleton embedding
might seem like a rather straightforward choice for solving the automatic
rigging problem, but it has its disadvantages. The most notable one is that it
makes the assumption that the user, or the algorithm itself, has predefined
skeletons which will fit the input model. This makes the performance of the
automatic rigging method limited to the diversity of characters that can be
rigged, and not self-sufficient in the case that it accepts skeletons prepared
by the users. 

The use of skeleton extraction circumvents the issue of needing a predefined
skeleton, by looking for the skeletal property within the mesh self. Pan et al.
\citep{paper2} take this skeletal approach, which will be explained next.

% what is the medial axis and why is it used
To extract the skeleton from a mesh, Pan et al. use the medial axis as a
guideline for finding the final animation skeleton. The medial axis consists of all points that have more than one
closest point on the boundary of the object. In other words, it consists of
point within the model that are centered with regards to the boundary of the
mesh. In case the medial axis is determined for a three dimensional shape, it most likely
is a surface (called the medial surface, as we have seen before in the case of
paper \citep{paper1}) but for a 2D object the medial axis will consists of
curves. These curves can be quite straightforwardly converted to a skeleton, as
it gives the exact centered placement for the bones within the mesh. Pan et al.
use 3D silhouettes, two dimensional projections with the depth information stored along
the silhouette, to find the medial axis of a 3D model.

To take the 3D silhouette from a mesh, first the optimal projection of the model
onto a two dimensional plane must be determined. An optimal projection is a
projection in which there is as little occlusion as possible, so that when
determining the medial axis, all parts of the character model are considered.
The optimal projection is thus considered the projection with the maximum
surface area. When this projection is determined, a global and a local search
are used to determine the 3D silhouette. In the global search the vertices
making up the 3D silhouette are determined. 

When the vertices belonging to the 3D silhouette are found using global search,
it is very likely these points are not connected in the mesh, due to
differences in depth between these vertices. The local search finds the shortest
route between every vertex of the 3D silhouette, and adds these in-between
vertices to the 3D silhouette vertices. Adding these vertices will add more
detail to the medial axis. %FIXME is this really the case?

After the 3D silhouette is found, the medial axis can be determined. This is
achieved by discretizing the silhouette in triangles, using Delaunay
Triangulation. For each triangle edge that is not on the boundary of the
silhouette, the midpoint is calculated. These points are then connected using
linear interpolation, creating one or multiple curves within the mesh. By
considering only the inner edges of the triangles, it is assured that none of
the curves make contact with the mesh boundary, which is desirable for the final
skeleton.

Because the application of the delaunay triangulation did not take the depth
into account, the medial axis calculation might be slightly off center. This is fixed
by looking for a perpendicular projection to the one used for the initial
silhouette creation. This is done for every curve by finding the projection
vector that is orthogonal on both the curve and the previous projection vector.
For this new projection the 3D silhouette is determined the same way as before.
The final refinement of the curve skeleton is  every element of the curve
finding the four nearest neighbours on the second silhouette, and then
interpolating between these four points.

When the medial axis is refined, the different curves need to be combined to a
single skeleton. All endpoints between each curve is considered a joint, and are
connected together. These, however are not all the joints in the skeleton only
the junctions between different limbs. To determine where the second degree
joints should be positioned in this skeleton, the authors look at the degree of
bending in the extracted curve. If the bending angle between positions on the curve is 
significant (which in this research means more than 18 degrees of bending), a
joint is added at that position.

\subsubsection{Combining embedding and extraction} Although skeleton extraction
can handle more generic cases than skeleton embedding, due to not needing any
prior knowledge on the topology of the character, there is also the
disadvantage in that the model must be expressive enough for the skeleton to be
correctly  extracted. We see this clearly in the way that
second degree joints need to be determined in the works of \citep{paper2}. Take
for example the case of a humanoid model standing in T-Pose (not an uncommon
pose to model a character in). If this skeleton extraction algorithm were to be run for
this particular model, it's output skeleton would be likely missing its elbow and knee
joints. 

\citep{paper3} suggests a method that combines embedding and extraction in such
a way that the extracted curve skeleton becomes the embedding space on which semantic
judgement can be made about what kind of character is being depicted by the
model.
The best-fitting template-skeleton can then be embedded in the model my aligning it with the curve skeleton..

The researchers use a curve extraction method called pseudonormal vector fields
which has been a result of earlier results, but any curve extractor that uses
distance fields could be used (so the method in \citep{paper2} is not ideal to
apply in this case). After the curve skeleton is extracted, the
curve is preprocessed. This preprocessing step makes sure that so called
symmetry segments come together at a single junction point. Symmetry segments
are limbs that should be paired together. So in case of a human, the arms would
be symmetry segments, and the legs would be symmetry segments. In case there are
two different junctions whose difference in distance is small to any endpoint of
the curve, the two junctions are merged together.
% They do not tlak about normalizing the size of the models, so i do not see how
% a single treshold could ever work

Now that we are certain that symmetric segments of the model come
together in junction points, this can be exploited towards determining what kind
of creature is being depicted by the model. To get any substantial understanding
of the topology of this curve skeleton, however, we need to determine what are
the symmetry segments and what is the symmetry axis. The symmetry axis is the
curve to which all extremities are connected (for a human model, this would be
considered the spine). To determine which is which, the
junction closest to the centroid of the character is found. The two longest
segments attached to this junction are considered the limbs, the remaining
segments are automatically part of the symmetry axis in case there are only one
or two segments at the junction left. In case there are more than two, the
remaining segments are first devided in groups that end up in other junction
points, and others that end up in an extremity. The symmetry axis segments are
then segments from the first group that make the biggest angle. In case there
are one or less segments available in here, segments from the scond group are
used as well. This is repeated for every new junction node found on the symmetry
axis, until the complete symmetry axis is found.

Being able to discover the symmetry axis using the method above, a
classification can be made about what the input model depicts. A very rough
first classification step uses the limbs to determine the character class. These
classes are:  a snake in case of zero junctions on the skeleton,
a bird (with its wings or legs fold up) or fish (single fin in the back)in case
of a single junction. The humanoid and quadruped skeletons fall into the next
category of two junction characters. The last class is for 3 junction
characters, under which humanoids with horns, quadrupeds with ears and birds
(with wings, tail and legs) fall.

To distinguish between characters of each class, the placement and orientation
of the junctions are checked, as well as the symmetry segment length. Because
of the length of the complete list, we will only mention a few concrete
characteristics the example looks for. For example, to distinguish between
fish and birds in the 1 junction class, the placement of the junction is
examined. If this junction is at the end of the symmetry axis, it is probably a
fish fin. If the junction is midway, it can be the wings of a bird in case the
angle betwee the symmetry segments is about 180 degrees, and else it will be the
legs of a bird. In the 2 junction case, the thickness of
limb is taken into account to distinguish between mammals and fish and birds.
The distinction between bipeds and quadrupeds is made by looking at the normal
vectors of the plane in which the symmetry segments fall for both junctions. If
these normal vectors point the same way, it is considered a quadruped, if not,
it is considered a biped. 

Using these rules and many others, we know the most likely character the model represents, and
what part each symmetry segment is of the final skeleton. Based on this
classification, an appopriate skeleton can be retrieved from a database full of
template skeletons. Each segment of this skeleton is then mapped on the desired
position of the curve skeleton. The junction position is done by keeping the
same ratio to the segment endpoints as is the case in the template skeleton.


%% It is a lot of work, but it only has to be done once.
%
%We clearly seesome approaches towar
%It makes a very clear space in which the final skeleton will be embedded. It
%also has a better selection procedure for choosing the to be fitted skeleton
%that this approach taken by \citep{paper3} does not remove all
%disadvantages of embedding and extraction. In the case of 
%It also has some limitations, which we will discuss in the evaluation.

\subsection{Skinning}
To pose the model using the skeleton, it still has to be decided how the model
is deformed by the moving skeleton. This process is called skinning. For the
skinning part there is not much diversity between the different researches. All
three apply a method called Linear Blend Skinning, which is a well established skinning method due
to its speeds and performance.

%Talk about how it works

%talk about some positive and negative approaches 


\subsection{Evaluation}
With the differences in methodology explained, we will now evaluate the
approaches regarding their performance, quality, self-sufficieny, generality and
further limitiations.

\subsection{Performance}
Speed is an important factor when it comes to the evaluation of the automatic rigging
methods. Ideally, we would like the time in which the rigging takes place is
faster than doing it by hand. \citep{paper1} has tested their algorithm on 16
different models. The shortest time was 12.6 seconds for a model containing 19.001
vertices. The longest time was 77.1 seconds for a model with 56.856 vertices.
%All papers are rather fast in their approach, we could possibly write some more in depth 
%sphere packing in paper 1 O(nb)
\citep{paper2} give the result of their algorithm applied to five different
character models. Their shortest time is 3.6 seconds for a model containing
16.834 faces and their longest time recorded is 15.1 seconds for a model
containing 52.895 faces.
\citep{paper3} only states the computation time for the model with biggest
volume, which is 30 seconds.

Although these performances can not be compaired side by side due to the test
being ran in different circumstances, all of them were applied on everyday
computers \footnote{Tests by \citep{paper1} were run on a 1.73 MHz Intel Core Duo
with 1GB RAM.\\ Tests by \citep{paper2} were run on a 1.6GHz Intel Core Dual PC
with 1GB RAM.\\
% Talk about where exactly the bottlenecks are.
% Paper 1: Discretization step. Although embedding time varies a lot due to the
% application of AStar, which is exponential.
% Paper 2: choice of first silhouette takes longest
% paper 3: voxel reconstruction
Test by \citep{paper3} were run on a 2.4-GHz Intel Core Dual PC with 1GB RAM.}
, making all three methods seem to perform fast enough to be considered
 a good automatic rigging method. The Intersting to note, is that the time
 complexity of the algorithm of \citep{paper2} is in $O(N)$, while the other
 approaches are in ($O(n^2)$), making their approach scale better with input
 size.

\subsection{Generality}
Ideally we would like the rigging methods applied to be as general as possible,
meaning that a single method could be used for all kinds of different input
character, and have a dersired outcome.

The method developed by \citep{paper1} has only been elaboratelty tested on the
 embedding of a biped skeleton \footnote{they mention also an experiment with a quadruped
skeleton and centaur skeleton embedding, but do not give any substantial information
about the process, giving the impression it is not at all extensively tested.}
template on different input character models. These
character models r.
Another interesting find is that objects that do not appear to be human-like can
be rigged using this same approach. In the works of 

Although we can say that the method of \citep{paper1} works fairly well for
quite a big range of modelsi, not limited to clearly biped models, it is lacking for a big range of other characters
as well. Most animals will not be succesfully rigged due to them being quadruped
(or higher)
in nature. In theory, the approach taken by \citep{paper1} could be extended for
non-humanoid models, by instead of fitting a single template to the input model,
try out all different possiblei skeleton
embeddings. After trying out these different embeddings, the embedding with the
smallest penalty can then be returned. This expansion to the algorithm, however,
has its own problems. Firstly, is the issue of computation time. All those different embeddings can give a 
huge overhead. Although we have seen that the most computation expensive part is
the distance field calculation in the discretization step, the embedding takes
at average one fifth of the complete computation time. Moreover, the
embedding time is worst case exponential due to the use of AStar, making the.
Another issue is the way the penalty calculation is performed. Although the 
% The penalty calculation is quite 

% Not a fault of the implementation of the authors, but inherent in the
% embedding itself. We create 
With this we can conclude that the approach of skeleton embedding by
\citep{paper1} is limited in generality, and making it more general brings new
problems, which are not easily fixable when maintaining the current approach.

% Paper 1 can fit humanoid skeletons in non humanoid forms
%Paper 1 can use new skeletons without needing threcalculate the weights, so making it more general, as well as self sufficient
%It does howev er use 
% even if paper 1 used more than a single skeleton throughout the whole embedding process, it has no criteria on which to fit the models.
% It could possibly for all embeddings check the least penalized embedding, but in the current state this is not implemented.
% Paper2 the generation of the curve skeleton from the medial axis only works in case the basic shape of the 
%paper 2 mentions that it only works for 
% Occlusion can happen even in the best of models, making their approach
% problematic.

% Problem paper 3: The detail of a skeleton migt be too high for a simpler input model.
% Slight 

\subsection{self-sufficiency}
%paper 1 is very reliant on the pose in which the mesh is delivered. It also uses quick hacks like " the feet are at the bottom" to perform well.
%paper 3 only wants a logical position of the mesh


\subsection{Robustness}
%Paper 1 gives the ability to give hints in case of wrong classification. Such a
%hint can be labeling the vertices like In case there are no vertices at the
%position that are desired to map the skeleton on, there is no way of saving the
%embedding. For example, in case the mesh has rather thin arms, and so the arms
%are not fitted correctly, there is no way of changing the layout, making user
%changes very limited because of the discretization step.

% Paper 2 global search seems robust? in worst case it can always add its
% neighbours to the mesh

\subsection{Limitations}
% In case of paper 2 no pre-existing motion capture data can be used
% In case of paper 2

\section{Usage}
% Usase of paper 1 seems good for novice users

%Use of paper 2 seems good for experience animators, who can more easily work
%with the limitation of 



%The usage of paper 3 could be a world wide database for animators, where they
%can add skeletons in a specific 

\section{Conclusion}
Give a small summary about what is said

What can we conclude about the 3 papers?  All 3 papers seem to have a slightly
different goal wanting to be reached.Paper 3 seems to focus on realistic models
the way their algorithm works (For example, thin legged creatures must be birds,
and so cannot be humans) but it does restrict creative freedom. In paper 1 this
creative freedom is very important to the researchers, but the final application
is very limited, with their a

What do I think is best?
To me, paper 2 seems the most promising in the way it works, as there is no
limitation as to what kind of creatures it can make. A big problem. however, is
the creation of the joint positions. Both relying on the model position showing
angles at every real joint position as well as creating a database of stored
joints is problematic, the first because it relies on the end users for creating
a pose, the latter because it loses the generality it had in the first place
(like we see in the works of paper 3). In my opinion, this part could best be
solved by another solution entirely. In my opinion the first solution is a
better one as the second.

do I have some views myself on how this could be improved?

\bibliographystyle{plain}
\bibliography{references}
\end{document}
